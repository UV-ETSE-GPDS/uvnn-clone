{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for training softmax regression, the code resides in **softmax_digits.py**. Algorithm is implemented in **softmax_example.py and nnbase.py**. nnbase can be adapted for variety of neural network types. \n",
    "The data comes from MNIST dataset, specifically https://www.kaggle.com/c/digit-recognizer. We have in total 42000 images encoded in 28x28 grayscale matrix. test set size is 28000. Solution right now has accuracy - 0.912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "sns.set(color_codes=True)\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "for f in os.listdir('../input'):\n",
    "    print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')\n",
    "\n",
    "\n",
    "from softmax_digits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read and preprocess data, see softmax_digits.py\n",
    "(X_train, y_train, X_dev, y_dev, X_test, y_test, X_fulltest) = get_data(num_train=40000, \n",
    "        num_dev=1000, num_test=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we try different batch size strategies\n",
    "nepoch = 5\n",
    "sz = len(y_train)\n",
    "print 'Training data size is', sz\n",
    "N = nepoch * len(y_train)\n",
    "k = 8 # minibatch size\n",
    "\n",
    "random.seed(10)\n",
    "def epoch_sch():\n",
    "    for i in xrange(nepoch):\n",
    "        for j in xrange(sz):\n",
    "            yield j\n",
    "\n",
    "def rand_sch():\n",
    "    for i in xrange(N):\n",
    "        yield random.randint(0, sz)\n",
    "\n",
    "def rand_minibatch(n, k):\n",
    "    # minibatch with size k\n",
    "    for _ in xrange (n / k):\n",
    "        yield [random.randint(0, sz) for _ in xrange(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sr = SoftmaxRegression(wv=zeros_like(X_train), dims=(784, 10), alpha=0.0001, reg=0.001)\n",
    "curve = sr.train_sgd(X_train, y_train, rand_minibatch(500000, 16), costevery=2000, devX=X_dev, devy=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts, costs, costdevs  = zip(*curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot train and dev errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.plot(5*array(counts), costs, color='b', marker='o', linestyle='-', label=r\"train_loss\")\n",
    "plt.plot(5*array(counts), costdevs, color='g', marker='o', linestyle='-', label=r\"validation_loss\")\n",
    "\n",
    "plt.title(r\"Learning Curve ($\\lambda=0.001$, costevery=5000)\")\n",
    "plt.xlabel(\"SGD Iterations\"); plt.ylabel(r\"Average $J(\\theta)$\"); \n",
    "plt.ylim(ymin=0, ymax=max(1.1*max(costs),3*min(costs)));\n",
    "plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_test = np.count_nonzero(sr.predict(X_test) == y_test) / double(len(y_test))\n",
    "print 'accuracy on test', accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate prediction for full data set\n",
    "y_fulltest = sr.predict(X_fulltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_fle(pred, fn):\n",
    "    ''' write file in csv format'''\n",
    "    df = pd.DataFrame()\n",
    "    df[\"ImageId\"] = range(1, len(pred) + 1)\n",
    "    df[\"Label\"] = pred\n",
    "    df.to_csv(\"../output/\" + fn, index=False)\n",
    "write_to_fle(y_fulltest, \"softmax_res.csv\")"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}